{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display, HTML\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Fix the dying kernel problem (only a problem in some installations - you can remove it, if it works without it)\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "\n",
    "Here's your best friend when working with PyTorch: https://pytorch.org/docs/stable/index.html.\n",
    "\n",
    "The beginning of this notebook shows that PyTorch tensors can be used exactly like numpy arrays. Later in the notebook additional features of tensors will be presented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating PyTorch tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n",
      "\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "a = np.array(\n",
    "    [[1.0, 2.0, 3.0], \n",
    "     [4.0, 5.0, 6.0], \n",
    "     [7.0, 8.0, 9.0]]\n",
    ")\n",
    "\n",
    "print(a)\n",
    "print()\n",
    "\n",
    "t = torch.tensor(\n",
    "    [[1.0, 2.0, 3.0], \n",
    "     [4.0, 5.0, 6.0], \n",
    "     [7.0, 8.0, 9.0]]\n",
    ")\n",
    "\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]\n",
      "\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n",
      "\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "l = [[1.0, 2.0, 3.0], \n",
    "     [4.0, 5.0, 6.0], \n",
    "     [7.0, 8.0, 9.0]]\n",
    "\n",
    "print(l)\n",
    "print()\n",
    "\n",
    "a = np.array(l)\n",
    "print(a)\n",
    "print()\n",
    "\n",
    "t = torch.tensor(l)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From a list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n",
      "\n",
      "[ 0  1  4  9 16 25 36 49 64 81]\n",
      "\n",
      "tensor([ 0,  1,  4,  9, 16, 25, 36, 49, 64, 81])\n"
     ]
    }
   ],
   "source": [
    "a = [i**2 for i in range(10)]\n",
    "\n",
    "print(a)\n",
    "print()\n",
    "print(np.array(a))\n",
    "print()\n",
    "print(torch.tensor(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.array(\n",
    "    [[1.0, 2.0, 3.0], \n",
    "     [4.0, 5.0, 6.0], \n",
    "     [7.0, 8.0, 9.0]]\n",
    ")\n",
    "\n",
    "t = torch.tensor(a)\n",
    "\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ready-made functions in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All zeros\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "\n",
      "All chosen value (variant 1)\n",
      "tensor([[7., 7., 7., 7.],\n",
      "        [7., 7., 7., 7.],\n",
      "        [7., 7., 7., 7.]])\n",
      "\n",
      "All chosen value (variant 2)\n",
      "tensor([[7., 7., 7., 7.],\n",
      "        [7., 7., 7., 7.],\n",
      "        [7., 7., 7., 7.]])\n",
      "\n",
      "Random integers\n",
      "[[3 0]\n",
      " [1 4]\n",
      " [2 0]]\n",
      "\n",
      "tensor([[6, 0],\n",
      "        [5, 2],\n",
      "        [5, 2]])\n",
      "\n",
      "Random values from the normal distribution\n",
      "[[  4.65209556 -17.13271022]\n",
      " [ 13.52525853  -5.85364907]\n",
      " [-11.11987627 -12.67993258]]\n",
      "\n",
      "tensor([[ 13.4592, -10.1822],\n",
      "        [  6.2218,   7.5400],\n",
      "        [ -9.5198,   4.3355]])\n"
     ]
    }
   ],
   "source": [
    "# All zeros\n",
    "a = torch.zeros((3, 4))\n",
    "print(\"All zeros\")\n",
    "print(a)\n",
    "print()\n",
    "\n",
    "# All a chosen value\n",
    "a = torch.full((3, 4), 7.0)\n",
    "print(\"All chosen value (variant 1)\")\n",
    "print(a)\n",
    "print()\n",
    "\n",
    "# or\n",
    "\n",
    "a = torch.zeros((3, 4))\n",
    "a[:] = 7.0\n",
    "print(\"All chosen value (variant 2)\")\n",
    "print(a)\n",
    "print()\n",
    "\n",
    "# Random integers\n",
    "\n",
    "print(\"Random integers\")\n",
    "a = np.random.randint(low=0, high=10, size=(3, 2))\n",
    "print(a)\n",
    "print()\n",
    "a = torch.randint(low=0, high=10, size=(3, 2))\n",
    "print(a)\n",
    "print()\n",
    "\n",
    "# Random values from the normal distribution (Gaussian)\n",
    "\n",
    "print(\"Random values from the normal distribution\")\n",
    "a = np.random.normal(loc=0, scale=10, size=(3, 2))\n",
    "print(a)\n",
    "print()\n",
    "a = torch.normal(mean=0, std=10, size=(3, 2))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing PyTorch tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing in 1D\n",
    "\n",
    "To obtain only specific values from a PyTorch tensor one can use so called slicing. It has the form\n",
    "\n",
    "**arr[low:high:step]**\n",
    "\n",
    "where low is the lowest index to be retrieved, high is the lowest index not to be retrieved and step indicates that every step element will be taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  tensor([ 0,  1,  4,  9, 16, 25, 36, 49, 64, 81])\n",
      "First 5 elements: tensor([ 0,  1,  4,  9, 16])\n",
      "Elements from index 3 to index 5: tensor([ 9, 16, 25])\n",
      "Last 3 elements (negative indexing): tensor([49, 64, 81])\n",
      "Every second element: tensor([ 0,  4, 16, 36, 64])\n",
      "Negative step a[::-1] to obtain reverse order does not work for tensors\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([i**2 for i in range(10)])\n",
    "\n",
    "print(\"Original: \", a)\n",
    "print(\"First 5 elements:\", a[:5])\n",
    "print(\"Elements from index 3 to index 5:\", a[3:6])\n",
    "print(\"Last 3 elements (negative indexing):\", a[-3:])\n",
    "print(\"Every second element:\", a[::2])\n",
    "\n",
    "print(\"Negative step a[::-1] to obtain reverse order does not work for tensors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing in 2D\n",
    "\n",
    "In two dimensions it works similarly, just the slicing is separate for every dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: \n",
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19],\n",
      "        [20, 21, 22, 23, 24]])\n",
      "\n",
      "First 2 elements of the first 3 row:\n",
      "tensor([[ 0,  1],\n",
      "        [ 5,  6],\n",
      "        [10, 11]])\n",
      "\n",
      "Middle 3 elements from the middle 3 rows:\n",
      "tensor([[ 6,  7,  8],\n",
      "        [11, 12, 13],\n",
      "        [16, 17, 18]])\n",
      "\n",
      "Bottom-right 3 by 3 submatrix (negative indexing):\n",
      "tensor([[12, 13, 14],\n",
      "        [17, 18, 19],\n",
      "        [22, 23, 24]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([i for i in range(25)]).reshape(5, 5)\n",
    "\n",
    "print(\"Original: \")\n",
    "print(a)\n",
    "print()\n",
    "print(\"First 2 elements of the first 3 row:\")\n",
    "print(a[:3, :2])\n",
    "print()\n",
    "print(\"Middle 3 elements from the middle 3 rows:\")\n",
    "print(a[1:4, 1:4])\n",
    "print()\n",
    "print(\"Bottom-right 3 by 3 submatrix (negative indexing):\")\n",
    "print(a[-3:, -3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting PyTorch tensor field values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: \n",
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19],\n",
      "        [20, 21, 22, 23, 24]])\n",
      "\n",
      "Middle values changed to 5\n",
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 5,  5,  5,  5,  9],\n",
      "        [10,  5,  5,  5, 14],\n",
      "        [15,  5,  5,  5, 19],\n",
      "        [20, 21, 22, 23, 24]])\n",
      "\n",
      "Second matrix\n",
      "tensor([[ 0,  0,  2],\n",
      "        [ 6, 12, 20],\n",
      "        [30, 42, 56]])\n",
      "\n",
      "Second matrix substituted into the middle of the first matrix\n",
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 5,  0,  0,  2,  9],\n",
      "        [10,  6, 12, 20, 14],\n",
      "        [15, 30, 42, 56, 19],\n",
      "        [20, 21, 22, 23, 24]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([i for i in range(25)]).reshape(5, 5)\n",
    "\n",
    "print(\"Original: \")\n",
    "print(a)\n",
    "print()\n",
    "\n",
    "a[1:4, 1:4] = 5.0\n",
    "\n",
    "print(\"Middle values changed to 5\")\n",
    "print(a)\n",
    "print()\n",
    "\n",
    "b = torch.tensor([i**2 - i for i in range(9)]).reshape(3, 3)\n",
    "\n",
    "print(\"Second matrix\")\n",
    "print(b)\n",
    "print()\n",
    "\n",
    "a[1:4, 1:4] = b\n",
    "\n",
    "print(\"Second matrix substituted into the middle of the first matrix\")\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations on PyTorch tensors\n",
    "\n",
    "It is important to remember that arithmetic operations on PyTorch tensors are always element-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  4],\n",
      "        [ 9, 16, 25],\n",
      "        [36, 49, 64]])\n",
      "\n",
      "tensor([[0.0000, 1.0000, 1.4142],\n",
      "        [1.7321, 2.0000, 2.2361],\n",
      "        [2.4495, 2.6458, 2.8284]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([i**2 for i in range(9)]).reshape((3, 3))\n",
    "print(a)\n",
    "print()\n",
    "\n",
    "b = torch.tensor([i**0.5 for i in range(9)]).reshape((3, 3))\n",
    "print(b)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Element-wise sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  2.0000,  5.4142],\n",
      "        [10.7321, 18.0000, 27.2361],\n",
      "        [38.4495, 51.6458, 66.8284]])\n"
     ]
    }
   ],
   "source": [
    "print(a + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Element-wise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0.0000,   1.0000,   5.6569],\n",
      "        [ 15.5885,  32.0000,  55.9017],\n",
      "        [ 88.1816, 129.6418, 181.0193]])\n"
     ]
    }
   ],
   "source": [
    "print(a * b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 11.5300,  12.5830,  13.5498],\n",
      "        [ 88.9501, 107.1438, 119.2157],\n",
      "        [241.6378, 303.3281, 341.4984]])\n",
      "\n",
      "tensor([[ 0.,  1.,  4.],\n",
      "        [ 9., 16., 25.],\n",
      "        [36., 49., 64.]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor a contained integers (type Long by default) and must be changed to the float type\n",
    "a = a.type(torch.FloatTensor)\n",
    "\n",
    "print(torch.matmul(a, b))\n",
    "print()\n",
    "\n",
    "# Multiplication by the identity matrix (to check it works as expected)\n",
    "id_matrix = torch.tensor(\n",
    "    [[1.0, 0.0, 0.0], \n",
    "     [0.0, 1.0, 0.0], \n",
    "     [0.0, 0.0, 1.0]]\n",
    ")\n",
    "\n",
    "print(torch.matmul(id_matrix, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 9, 1, 8, 8])\n",
      "\n",
      "Mean:  tensor(7.)\n",
      "\n",
      "Mean:  7.0\n"
     ]
    }
   ],
   "source": [
    "a = torch.randint(low=0, high=10, size=(5,))\n",
    "\n",
    "print(a)\n",
    "print()\n",
    "\n",
    "print(\"Mean: \", torch.sum(a) / len(a))\n",
    "print()\n",
    "\n",
    "# To get a single value use tensor.item()\n",
    "\n",
    "print(\"Mean: \", (torch.sum(a) / len(a)).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the mean of every row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6, 7, 0],\n",
      "        [1, 8, 3],\n",
      "        [2, 9, 7],\n",
      "        [6, 2, 8],\n",
      "        [8, 3, 2]])\n",
      "\n",
      "Mean: tensor([4.3333, 4.0000, 6.0000, 5.3333, 4.3333])\n",
      "Mean in the original matrix form:\n",
      "tensor([[4.3333],\n",
      "        [4.0000],\n",
      "        [6.0000],\n",
      "        [5.3333],\n",
      "        [4.3333]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randint(low=0, high=10, size=(5, 3))\n",
    "\n",
    "print(a)\n",
    "print()\n",
    "\n",
    "print(\"Mean:\", torch.sum(a, axis=1) / a.shape[1])\n",
    "\n",
    "print(\"Mean in the original matrix form:\")\n",
    "print((torch.sum(a, axis=1) / a.shape[1]).reshape(-1, 1))  # -1 calculates the right size to use all elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More complex operations\n",
    "\n",
    "Note that more complex tensor operations can only be performed on tensors. Numpy operations can be performed on numpy arrays but also directly on lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector to power 2 (element-wise)\n",
      "tensor([1., 4., 9.])\n",
      "\n",
      "Euler number to the power a (element-wise)\n",
      "tensor([ 2.7183,  7.3891, 20.0855])\n",
      "\n",
      "An even more complex expression\n",
      "tensor([0.6197, 1.8982, 4.8476])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1.0, 2.0, 3.0])\n",
    "\n",
    "print(\"Vector to power 2 (element-wise)\")\n",
    "print(torch.pow(a, 2))\n",
    "print()\n",
    "print(\"Euler number to the power a (element-wise)\")\n",
    "print(torch.exp(a))\n",
    "print()\n",
    "print(\"An even more complex expression\")\n",
    "print((torch.pow(a, 2) + torch.exp(a)) / torch.sum(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch basic operations tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.** Calculate the sigmoid (logistic) function on every element of the following array [0.3, 1.2, -1.4, 0.2, -0.1, 0.1, 0.8, -0.25] and print the last 5 elements. Use only tensor operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7685\n",
      "tensor([0.5744, 0.7685, 0.1978, 0.5498, 0.4750, 0.5250, 0.6900, 0.4378])\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "import math\n",
    "x = torch.tensor([0.3, 1.2, -1.4, 0.2, -0.1, 0.1, 0.8, -0.25])\n",
    "print(round(1/(1+math.exp(-1.2)), 4))\n",
    "sig_x = torch.sigmoid(x)\n",
    "print(sig_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.** Calculate the dot product of the following two vectors:<br/>\n",
    "$x = [3, 1, 4, 2, 6, 1, 4, 8]$<br/>\n",
    "$y = [5, 2, 3, 12, 2, 4, 17, 11]$<br/>\n",
    "a) by using element-wise mutliplication and torch.sum,<br/>\n",
    "b) by using torch.dot,<br/>\n",
    "b) by using torch.matmul and transposition (x.T)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(225)\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "𝑥=torch.tensor([3,1,4,2,6,1,4,8])\n",
    "𝑦=torch.tensor([5,2,3,12,2,4,17,11])\n",
    "prod = x.dot(y)\n",
    "print(prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.** Calculate the following expression<br/>\n",
    "$$\\frac{1}{1 + e^{-x_0 \\theta_0 - \\ldots - x_9 \\theta_9 - \\theta_{10}}}$$\n",
    "for<br/>\n",
    "$x = [1.2, 2.3, 3.4, -0.7, 4.2, 2.7, -0.5, -2.1, -3.3, 0.2]$<br/>\n",
    "$\\theta = [7.7, 0.33, -2.12, -1.73, 2.9, -5.8, -0.9, 12.11, 3.43, -0.5, 1.65]$<br/>\n",
    "and print the result. Use only tensor operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "𝑥=[1.2, 2.3, 3.4, -0.7, 4.2, 2.7, -0.5, -2.1, -3.3, 0.2]\n",
    "t=[7.7, 0.33, -2.12, -1.73, 2.9, -5.8, -0.9, 12.11, 3.43, -0.5]\n",
    "suma=0\n",
    "for a, b in zip(x, t):\n",
    "    suma+= (a * b)\n",
    "\n",
    "suma += 1.65\n",
    "suma = -suma\n",
    "print(round((1/(1+math.exp(suma))), 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor gradients\n",
    "\n",
    "Tensors are designed to be used in neural networks. Their most important functionality is automatic gradient and backward propagation calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n"
     ]
    }
   ],
   "source": [
    "w = 1.0\n",
    "f_w = math.log(w * math.exp(3*w))\n",
    "f_pw = 1/ (w+3)\n",
    "print(f_pw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out=35.0\n",
      "\n",
      "gradient\n",
      "tensor([[12.,  3.],\n",
      "        [27.,  3.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[2., -1.], [3., 1.]], requires_grad=True)\n",
    "out = x.pow(3).sum()  # the actual derivative is 3*x^2\n",
    "print(\"out={}\".format(out))\n",
    "print()\n",
    "\n",
    "out.backward()\n",
    "print(\"gradient\")\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4.,  2., -1.])\n",
      "tensor([ 2., -1.,  3.])\n",
      "tensor([ 0.1807,  0.0904, -0.0452])\n",
      "tensor([ 0.0904, -0.0452,  0.1355])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([2., -1., 3.], requires_grad=True)\n",
    "w = torch.tensor([4., 2., -1.], requires_grad=True)\n",
    "\n",
    "y = torch.sum(x * w)\n",
    "\n",
    "y.backward()\n",
    "print(x.grad)\n",
    "print(w.grad)\n",
    "\n",
    "x.grad.data.zero_()\n",
    "w.grad.data.zero_()\n",
    "\n",
    "y = torch.sigmoid(torch.sum(x * w))\n",
    "\n",
    "y.backward()\n",
    "print(x.grad)\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation\n",
    "\n",
    "In this section we train weights $w$ of a simple model $y = \\text{sigmoid}(w * x)$ to obtain $y = 0.65$ on $x = [2.0, -1.0, 3.0]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9526, grad_fn=<SigmoidBackward>)\n",
      "x\n",
      "tensor([ 2., -1.,  3.])\n",
      "x.grad\n",
      "None\n",
      "w\n",
      "tensor([ 4.,  2., -1.], requires_grad=True)\n",
      "\n",
      "\n",
      "w\n",
      "tensor([ 3.9945,  2.0027, -1.0082], requires_grad=True)\n",
      "w.grad\n",
      "tensor([ 0.0547, -0.0273,  0.0820])\n",
      "y\n",
      "tensor(0.9526, grad_fn=<SigmoidBackward>)\n",
      "loss\n",
      "tensor(0.0916, grad_fn=<PowBackward0>)\n",
      "\n",
      "\n",
      "w\n",
      "tensor([ 3.9889,  2.0055, -1.0166], requires_grad=True)\n",
      "w.grad\n",
      "tensor([ 0.0563, -0.0281,  0.0844])\n",
      "y\n",
      "tensor(0.9508, grad_fn=<SigmoidBackward>)\n",
      "loss\n",
      "tensor(0.0905, grad_fn=<PowBackward0>)\n",
      "\n",
      "\n",
      "w\n",
      "tensor([ 3.9831,  2.0084, -1.0253], requires_grad=True)\n",
      "w.grad\n",
      "tensor([ 0.0579, -0.0290,  0.0869])\n",
      "y\n",
      "tensor(0.9489, grad_fn=<SigmoidBackward>)\n",
      "loss\n",
      "tensor(0.0894, grad_fn=<PowBackward0>)\n",
      "\n",
      "\n",
      "w\n",
      "tensor([ 3.6599,  2.1701, -1.5102], requires_grad=True)\n",
      "w.grad\n",
      "tensor([ 6.1291e-06, -3.0645e-06,  9.1936e-06])\n",
      "y\n",
      "tensor(0.6500, grad_fn=<SigmoidBackward>)\n",
      "loss\n",
      "tensor(4.5365e-11, grad_fn=<PowBackward0>)\n",
      "\n",
      "\n",
      "w\n",
      "tensor([ 3.6599,  2.1701, -1.5102], requires_grad=True)\n",
      "w.grad\n",
      "tensor([ 5.0985e-06, -2.5493e-06,  7.6478e-06])\n",
      "y\n",
      "tensor(0.6500, grad_fn=<SigmoidBackward>)\n",
      "loss\n",
      "tensor(3.1392e-11, grad_fn=<PowBackward0>)\n",
      "\n",
      "\n",
      "w\n",
      "tensor([ 3.6599,  2.1701, -1.5102], requires_grad=True)\n",
      "w.grad\n",
      "tensor([ 4.4477e-06, -2.2238e-06,  6.6715e-06])\n",
      "y\n",
      "tensor(0.6500, grad_fn=<SigmoidBackward>)\n",
      "loss\n",
      "tensor(2.3888e-11, grad_fn=<PowBackward0>)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.tensor([2., -1., 3.], requires_grad=False)\n",
    "w = torch.tensor([4., 2., -1.], requires_grad=True)\n",
    "target = 0.65\n",
    "\n",
    "print(torch.sigmoid(torch.sum(x * w)))\n",
    "\n",
    "print(\"x\")\n",
    "print(x)\n",
    "print(\"x.grad\")\n",
    "print(x.grad)\n",
    "print(\"w\")\n",
    "print(w)\n",
    "print()\n",
    "print()\n",
    "\n",
    "optimizer = optim.SGD([w], lr=0.1)\n",
    "\n",
    "losses = []\n",
    "n_epochs = 100\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    y = torch.sigmoid(torch.sum(x * w))\n",
    "    loss = torch.pow(y - target, 2)\n",
    "    loss.backward()\n",
    "    losses.append(loss.item())\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch < 3 or epoch > 96:\n",
    "        print(\"w\")\n",
    "        print(w)\n",
    "        print(\"w.grad\")\n",
    "        print(w.grad)\n",
    "        print(\"y\")\n",
    "        print(y)\n",
    "        print(\"loss\")\n",
    "        print(loss)\n",
    "        print()\n",
    "        print()\n",
    "        \n",
    "sns.lineplot(x=np.arange(n_epochs), y=losses).set_title('Training loss')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proper PyTorch model with a fully-connected layer\n",
    "\n",
    "A fully-connected layer is represented by torch.nn.Linear. Its parameters are:\n",
    "  - in_features - the number of input neurons,\n",
    "  - out_features - the number of output neurons,\n",
    "  - bias - boolean if bias should be included.\n",
    "  \n",
    "Documentation: https://pytorch.org/docs/stable/generated/torch.nn.Linear.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedNetworkModel(nn.Module):\n",
    "    def __init__(self, seed):\n",
    "        super().__init__()\n",
    "\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "\n",
    "        self.fc = nn.Linear(2, 1, bias=False)\n",
    "\n",
    "        self.fc.weight.data = torch.tensor([1., -1.], requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w\n",
      "tensor([ 0.9925, -1.0075])\n",
      "w.grad\n",
      "tensor([0.0750, 0.0750])\n",
      "y\n",
      "tensor(0.5000, grad_fn=<SigmoidBackward>)\n",
      "loss\n",
      "tensor(0.0225, grad_fn=<PowBackward0>)\n",
      "\n",
      "\n",
      "w\n",
      "tensor([ 0.9852, -1.0148])\n",
      "w.grad\n",
      "tensor([0.0731, 0.0731])\n",
      "y\n",
      "tensor(0.5037, grad_fn=<SigmoidBackward>)\n",
      "loss\n",
      "tensor(0.0214, grad_fn=<PowBackward0>)\n",
      "\n",
      "\n",
      "w\n",
      "tensor([ 0.9781, -1.0219])\n",
      "w.grad\n",
      "tensor([0.0713, 0.0713])\n",
      "y\n",
      "tensor(0.5074, grad_fn=<SigmoidBackward>)\n",
      "loss\n",
      "tensor(0.0203, grad_fn=<PowBackward0>)\n",
      "\n",
      "\n",
      "w\n",
      "tensor([ 0.7236, -1.2764])\n",
      "w.grad\n",
      "tensor([0.0072, 0.0072])\n",
      "y\n",
      "tensor(0.6344, grad_fn=<SigmoidBackward>)\n",
      "loss\n",
      "tensor(0.0002, grad_fn=<PowBackward0>)\n",
      "\n",
      "\n",
      "w\n",
      "tensor([ 0.7229, -1.2771])\n",
      "w.grad\n",
      "tensor([0.0071, 0.0071])\n",
      "y\n",
      "tensor(0.6348, grad_fn=<SigmoidBackward>)\n",
      "loss\n",
      "tensor(0.0002, grad_fn=<PowBackward0>)\n",
      "\n",
      "\n",
      "w\n",
      "tensor([ 0.7222, -1.2778])\n",
      "w.grad\n",
      "tensor([0.0069, 0.0069])\n",
      "y\n",
      "tensor(0.6351, grad_fn=<SigmoidBackward>)\n",
      "loss\n",
      "tensor(0.0002, grad_fn=<PowBackward0>)\n",
      "\n",
      "\n",
      "tensor(0.6354, grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([-1.0, -1.0])\n",
    "target = 0.65\n",
    "\n",
    "fc_neural_net = FullyConnectedNetworkModel(seed=6789)\n",
    "\n",
    "optimizer = optim.SGD(fc_neural_net.parameters(), lr=0.1)\n",
    "\n",
    "losses = []\n",
    "n_epochs = 100\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    y = fc_neural_net(x)\n",
    "    loss = torch.pow(y - target, 2)\n",
    "    loss.backward()\n",
    "    losses.append(loss.item())\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch < 3 or epoch > 96:\n",
    "        print(\"w\")\n",
    "        print(fc_neural_net.fc.weight.data)\n",
    "        print(\"w.grad\")\n",
    "        print(next(fc_neural_net.parameters()).grad)\n",
    "        print(\"y\")\n",
    "        print(y)\n",
    "        print(\"loss\")\n",
    "        print(loss)\n",
    "        print()\n",
    "        print()\n",
    "        \n",
    "print(fc_neural_net(torch.tensor([-1.0, -1.0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding layer\n",
    "\n",
    "An embedding layer is represented by torch.nn.Embedding. Its main parameters are:\n",
    "  - num_embeddings - the number of ids to embed,\n",
    "  - embedding_dim - the dimension of the embedding vector.\n",
    "  \n",
    "Documentation: https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html\n",
    "\n",
    "In the example below we will have 3 movies and 3 users. The movies have already trained representations:\n",
    "  - $m0 = [2.0, 0.3, 0.5]$\n",
    "  - $m1 = [-1.7, 1.2, 1.4]$\n",
    "  - $m2 = [0.8, -1.5, -0.9]$\n",
    "where the three dimensions represent: level of violence, positive message, language (from foul to decent).\n",
    "\n",
    "We want to find user embeddings so that:\n",
    "  - user 0 likes movie 0 and dislikes movie 1 and 2,\n",
    "  - user 1 likes movie 1 and dislikes movie 0 and 2,\n",
    "  - user 2 likes movie 2 and dislikes movie 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingNetworkModel(nn.Module):\n",
    "    def __init__(self, seed):\n",
    "        super().__init__()\n",
    "\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "\n",
    "        self.embedding = nn.Embedding(3, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        user_id = x[0]\n",
    "        item_repr = x[1]\n",
    "        \n",
    "        y = self.embedding(user_id) * item_repr\n",
    "        y = torch.sum(y)\n",
    "        y = torch.sigmoid(y)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_ids = [torch.tensor(0), torch.tensor(1), torch.tensor(2)]\n",
    "items = [torch.tensor([2.0, 0.3, 0.5]), \n",
    "         torch.tensor([-1.7, 1.2, 1.4]), \n",
    "         torch.tensor([0.8, -1.5, -0.9])]\n",
    "responses = [1, 0, 0, 0, 1, 0, 0, 0, 1]\n",
    "data = [(user_ids[user_id], items[item_id]) for user_id in range(3) for item_id in range(3)]\n",
    "\n",
    "embedding_nn = EmbeddingNetworkModel(seed=6789)\n",
    "\n",
    "optimizer = optim.SGD(embedding_nn.parameters(), lr=0.1)\n",
    "\n",
    "losses = []\n",
    "n_epochs = 1000\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        user_id = data[i][0]\n",
    "        item_repr = data[i][1]\n",
    "        \n",
    "        y = embedding_nn((user_id, item_repr))\n",
    "        if i == 0:\n",
    "            loss = torch.pow(y - responses[i], 2)\n",
    "        else:\n",
    "            loss += torch.pow(y - responses[i], 2)\n",
    "    \n",
    "    loss.backward()\n",
    "    losses.append(loss.item())\n",
    "    optimizer.step()\n",
    "\n",
    "sns.lineplot(x=np.arange(n_epochs), y=losses).set_title('Training loss')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for user 0\n",
      "tensor([ 3.2125,  3.5110, -0.7015], grad_fn=<EmbeddingBackward>)\n",
      "Representation for item 0\n",
      "tensor([2.0000, 0.3000, 0.5000])\n",
      "Score=1.0\n",
      "\n",
      "Embedding for user 0\n",
      "tensor([ 3.2125,  3.5110, -0.7015], grad_fn=<EmbeddingBackward>)\n",
      "Representation for item 1\n",
      "tensor([-1.7000,  1.2000,  1.4000])\n",
      "Score=0.1\n",
      "\n",
      "Embedding for user 0\n",
      "tensor([ 3.2125,  3.5110, -0.7015], grad_fn=<EmbeddingBackward>)\n",
      "Representation for item 2\n",
      "tensor([ 0.8000, -1.5000, -0.9000])\n",
      "Score=0.11\n",
      "\n",
      "Embedding for user 1\n",
      "tensor([-2.1670,  0.9466,  0.5836], grad_fn=<EmbeddingBackward>)\n",
      "Representation for item 0\n",
      "tensor([2.0000, 0.3000, 0.5000])\n",
      "Score=0.02\n",
      "\n",
      "Embedding for user 1\n",
      "tensor([-2.1670,  0.9466,  0.5836], grad_fn=<EmbeddingBackward>)\n",
      "Representation for item 1\n",
      "tensor([-1.7000,  1.2000,  1.4000])\n",
      "Score=1.0\n",
      "\n",
      "Embedding for user 1\n",
      "tensor([-2.1670,  0.9466,  0.5836], grad_fn=<EmbeddingBackward>)\n",
      "Representation for item 2\n",
      "tensor([ 0.8000, -1.5000, -0.9000])\n",
      "Score=0.02\n",
      "\n",
      "Embedding for user 2\n",
      "tensor([-0.8861, -1.2192, -2.9579], grad_fn=<EmbeddingBackward>)\n",
      "Representation for item 0\n",
      "tensor([2.0000, 0.3000, 0.5000])\n",
      "Score=0.03\n",
      "\n",
      "Embedding for user 2\n",
      "tensor([-0.8861, -1.2192, -2.9579], grad_fn=<EmbeddingBackward>)\n",
      "Representation for item 1\n",
      "tensor([-1.7000,  1.2000,  1.4000])\n",
      "Score=0.02\n",
      "\n",
      "Embedding for user 2\n",
      "tensor([-0.8861, -1.2192, -2.9579], grad_fn=<EmbeddingBackward>)\n",
      "Representation for item 2\n",
      "tensor([ 0.8000, -1.5000, -0.9000])\n",
      "Score=0.98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "id_pairs = [(user_id, item_id) for user_id in range(3) for item_id in range(3)]\n",
    "\n",
    "for id_pair in id_pairs:\n",
    "    print(\"Embedding for user {}\".format(id_pair[0]))\n",
    "    print(embedding_nn.embedding(user_ids[id_pair[0]]))\n",
    "    print(\"Representation for item {}\".format(id_pair[1]))\n",
    "    print(items[id_pair[1]])\n",
    "    print(\"Score={}\".format(round(embedding_nn((user_ids[id_pair[0]], items[id_pair[1]])).item(), 2)))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
